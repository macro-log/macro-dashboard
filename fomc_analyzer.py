import re
from collections import Counter
import pandas as pd
import json

# -----------------------------
# í…ìŠ¤íŠ¸ ì •ë¦¬ (ì „ì²˜ë¦¬)
# -----------------------------
def clean_text(text):
    text = text.lower()
    # ì˜ë¬¸ìë§Œ ë‚¨ê¸°ê¸°
    text = re.sub(r'[^a-z\s]', ' ', text)
    words = text.split()

    # ê¸ˆìœµ ë„ë©”ì¸ ë§ì¶¤í˜• ë¶ˆìš©ì–´ ì œê±°
    stopwords = set([
        "the","and","of","to","in","a","for","is","on",
        "that","with","as","by","at","an","be","this","it",
        "were","was","are","from","or","but","not","have",
        "had","has","their","they","them","its", "will", "would",
        "could", "should", "been", "been"
    ])

    words = [w for w in words if w not in stopwords and len(w) > 3]
    return words

# -----------------------------
# ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
# -----------------------------
def get_word_freq(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            text = f.read()
        words = clean_text(text)
        return Counter(words)
    except FileNotFoundError:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return Counter()

# -----------------------------
# ë³€í™”ìœ¨ ê³„ì‚° ë° JSON ì €ì¥
# -----------------------------
def analyze_and_save(current_file, compare_file, output_json):
    print(f"\n[{output_json}] ë¶„ì„ ì¤‘...")
    
    current_freq = get_word_freq(current_file)
    compare_freq = get_word_freq(compare_file)
    
    if not current_freq or not compare_freq:
        print("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    rows = []
    # ë‘ ì˜ì‚¬ë¡ì˜ ëª¨ë“  ë‹¨ì–´ ì§‘í•©
    all_words = set(current_freq.keys()).union(set(compare_freq.keys()))

    for word in all_words:
        cur = current_freq.get(word, 0)
        comp = compare_freq.get(word, 0)
        
        # ë³€í™”ìœ¨ ê³„ì‚° (ë¶„ëª¨ê°€ 0ì¼ ê²½ìš° ì²˜ë¦¬)
        if comp == 0:
            change_rate = float('inf') if cur > 0 else 0
        else:
            change_rate = (cur - comp) / comp

        rows.append({"word": word, "current": cur, "compare": comp, "change_rate": change_rate})

    # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° ì •ë ¬ (ë³€í™”í­ì´ ê°€ì¥ í° ë‹¨ì–´ìˆœ)
    df = pd.DataFrame(rows)
    df = df.sort_values(by="change_rate", key=lambda x: x.abs(), ascending=False)
    
    # ğŸ’¡ ì›¹ì‚¬ì´íŠ¸ ì—°ë™ í•µì‹¬: JSON íŒŒì¼ë¡œ ì €ì¥
    top_words = df.head(50) # ìƒìœ„ 50ê°œë§Œ ì €ì¥
    top_words.to_json(output_json, orient="records", force_ascii=False)
    print(f"âœ… {output_json} íŒŒì¼ ìƒì„± ì™„ë£Œ!")

# -----------------------------
# ì‹¤í–‰
# -----------------------------
if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œ ì„¤ì • (signal9 í´ë” ì•ˆì— ìˆì–´ì•¼ í•¨)
    current = "current_minutes.txt"
    previous = "previous_minutes.txt"
    last_year = "last_year_minutes.txt"

    # 1. ì§ì „ ì˜ì‚¬ë¡ ëŒ€ë¹„ ë¶„ì„
    analyze_and_save(current, previous, "change_vs_previous.json")
    
    # 2. 1ë…„ ì „ ëŒ€ë¹„ ë¶„ì„
    analyze_and_save(current, last_year, "change_vs_last_year.json")